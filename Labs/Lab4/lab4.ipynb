{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Information Processing and Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document organizing, annotation, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.graphics', 'rec.autos', 'sci.crypt', 'talk.politics.guns']\n",
    "collection = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: holland@CS.ColoState.EDU (douglas craig holland)\n",
      "Subject: What would happen if export restrictions violated?\n",
      "Nntp-Posting-Host: beethoven.cs.colostate.edu\n",
      "Organization: Colorado State University, Computer Science Department\n",
      "Lines: 15\n",
      "\n",
      "\n",
      "OK, I heard a lot of talk about the NSA's infamous control over encryption\n",
      "export through the ITAR.  Here's a question.  Say I develop this great new\n",
      "encryption system, and I want to sell my software worldwide.  The thought\n",
      "police then come in and say \"This algorithm is a threat to national security.\n",
      "You will not be permitted to export it.\"  At this point, what kind of trouble\n",
      "could I get into if I ignored the ITAR and sold my program to international\n",
      "customers anyway?\n",
      "\n",
      "Doug Holland\n",
      "\n",
      "-- \n",
      "|  Doug Holland                | Anyone who tries to take away my freedom  |\n",
      "|  holland@cs.colostate.edu    | of speech will have to pry it from my     |\n",
      "|  PGP key available by E-mail | cold, dead lips!!                         |\n",
      "\n",
      "2\n",
      "sci.crypt\n",
      "\n",
      "From: strnlght@netcom.com (David Sternlight)\n",
      "Subject: Re: Once tapped, your code is no good any more.\n",
      "Organization: DSI/USCRPAC\n",
      "Distribution: na\n",
      "Lines: 26\n",
      "\n",
      "In article <a_rubin.735496128@dsg4.dse.beckman.com>\n",
      "a_rubin@dsg4.dse.beckman.com (Arthur Rubin) writes:\n",
      "\n",
      ">\n",
      ">I wouldn't think so.  Asking people to trust a secret algorithm seems\n",
      ">unsound to me.\n",
      "\n",
      "Maybe so, but it's quite common. There are millions of Macintosh users who\n",
      "have no idea what's in Apple's patented ROMs. Many have modems connected.\n",
      "How do you know all your business secrets aren't being stolen? Answer:\n",
      "1. Because you trust Apple;\n",
      "2. Because if any such attempt, however sophicsticated, came out, it would\n",
      "destroy Apple's credibility forever.\n",
      "\n",
      "In the Clipper case, a representative body of experts is going to be allowed\n",
      "to audit it, and we'll have assurances (maybe even from the President) that\n",
      "other than the escrowed keys there are no back doors. While some may not\n",
      "have confidence in that (I am not among them), it's a lot more assurance\n",
      "than we get for many things we routinely trust in everyday life.\n",
      "\n",
      "David\n",
      "-- \n",
      "David Sternlight         Great care has been taken to ensure the accuracy of\n",
      "                         our information, errors and omissions excepted.  \n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "sci.crypt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(collection.data[i])\n",
    "    print(collection.target[i])\n",
    "    print(collection.target_names[collection.target[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data is in a text format, we need to process it in order to extract useful information. Let's use TFIDF from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=False)\n",
    "\n",
    "X = vectorizer.fit_transform(collection.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1545, 26904)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' ... 'zyda' 'zyeh' 'zyxel']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Cluster the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Extract the vector space of the 20 Newsgroup (use collection.data instruction to ignore\n",
    "the class variable), and cluster the collection using agglomerative clustering from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering().fit(X.toarray())\n",
    "\n",
    "# Note: we convert X to an array because it's needed by AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "# Print all distinct labels\n",
    "print(set(clustering.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to parameterize the number of clusters and the linkage method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_clusters = 20\n",
    "# choose the best number for n_clusters\n",
    "single = AgglomerativeClustering(linkage='average', n_clusters=n_clusters, metric='cosine').fit(X.toarray())\n",
    "\n",
    "complete = AgglomerativeClustering(linkage='average', n_clusters=n_clusters, metric='cosine').fit(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_labels = single.fit_predict(X.toarray())\n",
    "complete_labels = complete.fit_predict(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[1 3 1 ... 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(single_labels)\n",
    "print(complete_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Plot the learned dendogram using the cluster.hierarchy.dendrogram package from scipy.\n",
    "Compare the clustering solutions produced under single and complete linkage criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions of Z and labels must be consistent.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m Z \u001b[38;5;241m=\u001b[39m linkage(X\u001b[38;5;241m.\u001b[39mtoarray(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdendrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\Lovaion\\University\\2nd Year\\Erasmus\\Information Processing and Retrieval\\.venv\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:3282\u001b[0m, in \u001b[0;36mdendrogram\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color)\u001b[0m\n\u001b[0;32m   3280\u001b[0m         len_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   3281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m!=\u001b[39m len_labels:\n\u001b[1;32m-> 3282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions of Z and labels must be consistent.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3284\u001b[0m is_valid_linkage(Z, throw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3285\u001b[0m Zs \u001b[38;5;241m=\u001b[39m Z\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions of Z and labels must be consistent."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Z = linkage(X.toarray(), 'single', metric='cosine')\n",
    "plt.figure()\n",
    "dendrogram(Z, labels=collection.target_names, orientation='right')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "Z = linkage(X.toarray(), 'complete', metric='cosine')\n",
    "plt.figure()\n",
    "dendrogram(Z, labels=collection.target_names, orientation='right')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. Evaluate the clustering solution by computing an internal measure (e.g. silhouette) and an\n",
    "external measure (e.g. adjusted rand index) for the produced clustering solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for single linkage: 0.26392018268553363\n",
      "Silhouette score for complete linkage: 0.02735054639193526\n",
      "Adjusted Rand score for single linkage: -3.059877070379207e-05\n",
      "Adjusted Rand score for complete linkage: 0.015177362174200237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "sscore = silhouette_score(X, single_labels, metric='cosine')\n",
    "cscore = silhouette_score(X, complete_labels, metric='cosine')\n",
    "\n",
    "# for the random score we need the true labels\n",
    "true_labels = collection.target\n",
    "\n",
    "arsingle = adjusted_rand_score(true_labels, single_labels)\n",
    "arcomplete = adjusted_rand_score(true_labels, complete_labels)\n",
    "\n",
    "print(f\"Silhouette score for single linkage: {sscore}\")\n",
    "print(f\"Silhouette score for complete linkage: {cscore}\")\n",
    "print(f\"Adjusted Rand score for single linkage: {arsingle}\")\n",
    "print(f\"Adjusted Rand score for complete linkage: {arcomplete}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
